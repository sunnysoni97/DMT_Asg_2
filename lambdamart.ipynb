{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This jupyter notebook is running on Python 3.7.9\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import functions.preprocessing as prep\n",
    "from dask.distributed import Client\n",
    "import joblib\n",
    "\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyltr\n",
    "import pickle\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(\"This jupyter notebook is running on Python \" + platform.python_version())\n",
    "# It's good practice to assert packages requirements at the beginning of a script:\n",
    "assert sys.version_info >= (3, 6)  # Tested with Python==3.7.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ramon\\Desktop\\DMT_Asg_2\\functions\\preprocessing.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  return dataFrame.drop('date_time', 1)\n"
     ]
    }
   ],
   "source": [
    "training_set_file_path = 'data/training_set_VU_DM.csv'\n",
    "test_set_file_path = 'data/test_set_VU_DM.csv'\n",
    "training_data = pd.read_csv(training_set_file_path)\n",
    "test_data = pd.read_csv(test_set_file_path)\n",
    "\n",
    "training_data = prep.parseDateTime(training_data)\n",
    "training_data = prep.replaceNaN(training_data)\n",
    "training_data = prep.mergeComps(training_data)\n",
    "\n",
    "test_data = prep.parseDateTime(test_data)\n",
    "test_data = prep.replaceNaN(test_data)\n",
    "test_data = prep.mergeComps(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (training_data['booking_bool'] == 1),\n",
    "    (training_data['click_bool'] == 1 ) & (training_data['booking_bool'] == 0),\n",
    "    (training_data['click_bool'] == 0),\n",
    "    ]\n",
    "values = [5, 1, 0]\n",
    "training_data['relevancy'] = np.select(conditions, values)\n",
    "#training_data['relevancy'] = training_data['relevancy'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_y = training_data.relevancy\n",
    "search_id = training_data.srch_id.tolist()\n",
    "search_id_test = test_data.srch_id.tolist()\n",
    "prop_id_test = test_data.prop_id.tolist()\n",
    "splitNumber = int(len(training_data_y)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['site_id', 'visitor_location_country_id', 'prop_country_id', 'prop_starrating', 'prop_brand_bool', 'prop_location_score1',\n",
    "                              'prop_log_historical_price', 'promotion_flag', 'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
    "                              'srch_saturday_night_bool', 'random_bool', 'comp_rate', 'comp_inv', 'comp_rate_percent_diff']\n",
    "training_data_x = training_data[columns]\n",
    "test_data = test_data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_x = training_data_x[splitNumber:]\n",
    "val_data_y = training_data_y[splitNumber:]\n",
    "val_search_id = search_id[splitNumber:]\n",
    "training_data_x = training_data_x[:splitNumber]\n",
    "training_data_y = training_data_y[:splitNumber]\n",
    "training_search_id = search_id[:splitNumber]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(training_data_x)\n",
    "training_data_x = scaler.transform(training_data_x)\n",
    "scaler = StandardScaler().fit(val_data_x)\n",
    "val_data_x = scaler.transform(val_data_x)\n",
    "scaler = StandardScaler().fit(test_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Client = Client(processes=False)\n",
    "metric = pyltr.metrics.NDCG(k=5)\n",
    "\n",
    "monitor = pyltr.models.monitors.ValidationMonitor(val_data_x, val_data_y, val_search_id, metric=metric,\n",
    "                                                      stop_after=50)\n",
    "model = pyltr.models.LambdaMART(\n",
    "    metric=metric,\n",
    "    n_estimators=1000,\n",
    "    max_features=0.5,\n",
    "    learning_rate=0.02,\n",
    "    query_subsample=0.5,\n",
    "    max_leaf_nodes=10,\n",
    "    min_samples_leaf=64,\n",
    "    verbose=1,\n",
    ")\n",
    "#with joblib.parallel_backend('dask'):\n",
    "#    model.fit(training_data_x, training_data_y, training_search_id, monitor=monitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('finalized_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('lambda_model_1.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ramon\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "outputFrame = pd.DataFrame(columns=['srch_id','predictions', 'prop_id'])\n",
    "outputFrame.srch_id = search_id_test\n",
    "outputFrame.predictions = predictions\n",
    "outputFrame.prop_id = prop_id_test\n",
    "outputFrame = outputFrame.sort_values(['srch_id', 'predictions'], ascending = [True, False])\n",
    "outputFrame = outputFrame.drop(['predictions'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFrame.to_csv('loadedModelTest.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84b962f2f278f8c5f72c48a6636c1f10fd3d5b5d26c18f151a5696f5b5a7ec31"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
